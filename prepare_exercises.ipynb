{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "- The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "- In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "#1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "#2. Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n",
    "#3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n",
    "#4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n",
    "#5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "    - This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "    \n",
    "#6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "\n",
    "#7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "\n",
    "#8. For each dataframe, produce the following columns:\n",
    "\n",
    "    - title to hold the title\n",
    "    - original to hold the original article/post content\n",
    "    - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "    - stemmed to hold the stemmed version of the cleaned data.\n",
    "    - lemmatized to hold the lemmatized version of the cleaned data.\n",
    "    \n",
    "#9. Ask yourself:\n",
    "    - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/linhquach/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# We don't need to install nltk, it should come with anaconda, but nltk\n",
    "# does need to download some data.\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string_value):\n",
    "    #lowercase all letters in the text\n",
    "\n",
    "    article = original.lower()\n",
    "\n",
    "    # Normalizaton: Remove inconsistencies in unicode charater encoding.\n",
    "    # encode the strings into ASCII byte-strings (ignore non-ASCII characters)\n",
    "    # decode the byte-string back into a string\n",
    "\n",
    "    unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "    # remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "    article = re.sub(r\"[^a-z0-9\\s]\", '', article)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article= basic_clean(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(article):\n",
    "    # Create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    # Use the tokenizer\n",
    "    article = tokenizer.tokenize(article, return_str= True)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article= tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(article):\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # Check stemmer. It works.\n",
    "    ps.stem('Calling')\n",
    "    # Apply the stemmer to each word in our string.\n",
    "    stems =[ps.stem(word) for word in article.split()]\n",
    "    # Join our lists of words into a string again; assign to a variable to save changes\n",
    "    article_stemmed = ' '.join(stems)\n",
    "    return article_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_stemmed= stem(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erd and georg plya are influenti hungarian mathematician who contribut a lot to the field erdss name contain the hungarian letter o with doubl acut accent but is often incorrectli written as erdo or erd either by mistak or out of typograph necess'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(article):\n",
    "    # Create the Lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "    # Join our list of words into a string again; assign to a variable to save changes.\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lemmatized= lemmatize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erds and george plya are influential hungarian mathematician who contributed a lot to the field erdss name contains the hungarian letter o with double acute accent but is often incorrectly written a erdos or erds either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "    - This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article_lemmatized, extra_words= [], exclude_words=[]):\n",
    "    # standard English language stopwords list from nltk\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # remove 'exlude_words' from stopword_list to keep these\n",
    "    stopword_list= set(stopword_list) - set(exclude_words)\n",
    "    #Add in 'extra_words' to stopword_list\n",
    "    stopword_list= stopword_list.union(set(extra_words))\n",
    "    #split words\n",
    "    words= article_lemmatized.split()\n",
    "#     # you can add or remove from stopword list \n",
    "#     stopword_list.append('o')\n",
    "#     stopword_list.remove('not')\n",
    "#     stopword_list.append(\"'\")\n",
    "#     # Split words in lemmatized article.\n",
    "#     words = article_lemmatized.split()\n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # Join words in the list back into strings; assign to a variable to keep changes.\n",
    "    article_without_stopwords = ' '.join(filtered_words)\n",
    "    return article_without_stopwords\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_without_stopwords= remove_stopwords(article_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erds george plya influential hungarian mathematician contributed lot field erdss name contains hungarian letter double acute accent often incorrectly written erdos erds either mistake typographical necessity'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article, category):\n",
    "    # Attribute selector\n",
    "    title = article.select(\"[itemprop='headline']\")[0].text\n",
    "    \n",
    "    # article body\n",
    "    content = article.select(\"[itemprop='articleBody']\")[0].text\n",
    "    \n",
    "    output = {}\n",
    "    output[\"title\"] = title\n",
    "    output[\"content\"] = content\n",
    "    output[\"category\"] = category\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(category, base =\"https://inshorts.com/en/read/\"):\n",
    "    \"\"\"\n",
    "    This function takes in a category as a string. Category must be an available category in inshorts\n",
    "    Returns a list of dictionaries where each dictionary represents a single inshort article\n",
    "    \"\"\"\n",
    "    \n",
    "    # We concatenate our base_url with the category\n",
    "    url = base + category\n",
    "    \n",
    "    # Set the headers\n",
    "    headers = {\"User-Agent\": \"Mozilla/4.5 (compatible; HTTrack 3.0x; Windows 98)\"}\n",
    "\n",
    "    # Get the http response object from the server\n",
    "    response = get(url, headers=headers)\n",
    "\n",
    "    # Make soup out of the raw html\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # Ignore everything, focusing only on the news cards\n",
    "    articles = soup.select(\".news-card\")\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Iterate through every article tag/soup \n",
    "    for article in articles:\n",
    "        \n",
    "        # Returns a dictionary of the article's title, body, and category\n",
    "        article_data = get_article(article, category) \n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        output.append(article_data)\n",
    "    \n",
    "    # Return the list of dictionaries\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news_articles(categories):\n",
    "    \"\"\"\n",
    "    Takes in a list of categories where the category is part of the URL pattern on inshorts\n",
    "    Returns a dataframe of every article from every category listed\n",
    "    Each row in the dataframe is a single article\n",
    "    \"\"\"\n",
    "    all_inshorts = []\n",
    "\n",
    "    for category in categories:\n",
    "        all_category_articles = get_articles(category)\n",
    "        all_inshorts = all_inshorts + all_category_articles\n",
    "\n",
    "    df = pd.DataFrame(all_inshorts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "news_df = get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>UN panel uses $600mn in Iraqi funds to pay Kuw...</td>\n",
       "      <td>A UN commission on Tuesday used $600 million i...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Samoa's first female PM takes office after con...</td>\n",
       "      <td>Samoa's first female PM Fiame Naomi Mata'afa t...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1st person charged under Hong Kong national se...</td>\n",
       "      <td>The first person to be tried under the nationa...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6 killed after rains trigger landslides in ref...</td>\n",
       "      <td>Bangladeshi officials on Tuesday said that at ...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Gunmen on motorbikes attack village in Niger, ...</td>\n",
       "      <td>Armed men on motorbikes have killed at least 1...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Reliance Industries vaccinates 98% of workers,...   \n",
       "1    Musk criticises Apple's 'walled garden', cobal...   \n",
       "2    I will most likely not be on future earnings c...   \n",
       "3    Speculation around our plans for crypto not tr...   \n",
       "4    Factually incorrect: INOX on report of Amazon ...   \n",
       "..                                                 ...   \n",
       "143  UN panel uses $600mn in Iraqi funds to pay Kuw...   \n",
       "144  Samoa's first female PM takes office after con...   \n",
       "145  1st person charged under Hong Kong national se...   \n",
       "146  6 killed after rains trigger landslides in ref...   \n",
       "147  Gunmen on motorbikes attack village in Niger, ...   \n",
       "\n",
       "                                               content  category  \n",
       "0    Reliance Industries has said in a statement th...  business  \n",
       "1    Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "2    Tesla CEO and the world's second-richest perso...  business  \n",
       "3    Amazon on Monday denied speculations that it w...  business  \n",
       "4    INOX Leisure denied a report that claimed Amaz...  business  \n",
       "..                                                 ...       ...  \n",
       "143  A UN commission on Tuesday used $600 million i...     world  \n",
       "144  Samoa's first female PM Fiame Naomi Mata'afa t...     world  \n",
       "145  The first person to be tried under the nationa...     world  \n",
       "146  Bangladeshi officials on Tuesday said that at ...     world  \n",
       "147  Armed men on motorbikes have killed at least 1...     world  \n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codeup_blog(url):\n",
    "    \n",
    "    # Set the headers to show as Netscape Navigator on Windows 98, b/c I feel like creating an anomaly in the logs\n",
    "    headers = {\"User-Agent\": \"Mozilla/4.5 (compatible; HTTrack 3.0x; Windows 98)\"}\n",
    "\n",
    "    # Get the http response object from the server\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    title = soup.find(\"h1\").text\n",
    "    published_date = soup.time.text\n",
    "    \n",
    "    if len(soup.select(\".jupiterx-post-image\")) > 0:\n",
    "        blog_image = soup.select(\".jupiterx-post-image\")[0].picture.img[\"data-src\"]\n",
    "    else:\n",
    "        blog_image = None\n",
    "        \n",
    "    content = soup.select(\".jupiterx-post-content\")[0].text\n",
    "    \n",
    "    output = {}\n",
    "    output[\"title\"] = title\n",
    "    output[\"published_date\"] = published_date\n",
    "    output[\"blog_image\"] = blog_image\n",
    "    output[\"content\"] = content\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(urls):\n",
    "    # List of dictionaries\n",
    "    posts = [get_codeup_blog(url) for url in urls]\n",
    "    \n",
    "    return pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://codeup.com/codeups-data-science-career-accelerator-is-here/\",\n",
    "    \"https://codeup.com/data-science-myths/\",\n",
    "    \"https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\",\n",
    "    \"https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\",\n",
    "    \"https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Codeup_df = get_blog_articles(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>blog_image</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>September 30, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>October 31, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>October 17, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      published_date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  September 30, 2018   \n",
       "1                                 Data Science Myths    October 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...    October 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair     August 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...     August 14, 2018   \n",
       "\n",
       "                                          blog_image  \\\n",
       "0  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "1  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "2  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. For each dataframe, produce the following columns:\n",
    "\n",
    "    - title to hold the title\n",
    "    - original to hold the original article/post content\n",
    "    - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "    - stemmed to hold the stemmed version of the cleaned data.\n",
    "    - lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes(df): \n",
    "    df.rename(columns={'content': 'original'}, inplace=True)\n",
    "    df['clean']= df['original'].apply(basic_clean)\n",
    "    df['clean']= df['original'].apply(tokenize)\n",
    "    df['stemmed']= df['original'].apply(stem)\n",
    "    df['lemmatized']= df['original'].apply(lemmatize)\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using function on news_df\n",
    "news_edited_df= dataframes(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>relianc industri ha said in a statement that o...</td>\n",
       "      <td>Reliance Industries ha said in a statement tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "      <td>Tesla ' s billionaire CEO Elon Musk criticised...</td>\n",
       "      <td>tesla' billionair ceo elon musk criticis appl ...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "      <td>Tesla CEO and the world ' s second-richest per...</td>\n",
       "      <td>tesla ceo and the world' second-richest person...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>amazon on monday deni specul that it wa look t...</td>\n",
       "      <td>Amazon on Monday denied speculation that it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>inox leisur deni a report that claim amazon in...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  Musk criticises Apple's 'walled garden', cobal...   \n",
       "2  I will most likely not be on future earnings c...   \n",
       "3  Speculation around our plans for crypto not tr...   \n",
       "4  Factually incorrect: INOX on report of Amazon ...   \n",
       "\n",
       "                                            original  category  \\\n",
       "0  Reliance Industries has said in a statement th...  business   \n",
       "1  Tesla's billionaire CEO Elon Musk criticised A...  business   \n",
       "2  Tesla CEO and the world's second-richest perso...  business   \n",
       "3  Amazon on Monday denied speculations that it w...  business   \n",
       "4  INOX Leisure denied a report that claimed Amaz...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  Reliance Industries has said in a statement th...   \n",
       "1  Tesla ' s billionaire CEO Elon Musk criticised...   \n",
       "2  Tesla CEO and the world ' s second-richest per...   \n",
       "3  Amazon on Monday denied speculations that it w...   \n",
       "4  INOX Leisure denied a report that claimed Amaz...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  relianc industri ha said in a statement that o...   \n",
       "1  tesla' billionair ceo elon musk criticis appl ...   \n",
       "2  tesla ceo and the world' second-richest person...   \n",
       "3  amazon on monday deni specul that it wa look t...   \n",
       "4  inox leisur deni a report that claim amazon in...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  Reliance Industries ha said in a statement tha...  \n",
       "1  Tesla's billionaire CEO Elon Musk criticised A...  \n",
       "2  Tesla CEO and the world's second-richest perso...  \n",
       "3  Amazon on Monday denied speculation that it wa...  \n",
       "4  INOX Leisure denied a report that claimed Amaz...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at values\n",
    "news_edited_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using function on Codeup_df\n",
    "Codeup_edited_df= dataframes(Codeup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>blog_image</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>September 30, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "      <td>The rumors are true ! The time has arrived. Co...</td>\n",
       "      <td>the rumor are true! the time ha arrived. codeu...</td>\n",
       "      <td>The rumor are true! The time ha arrived. Codeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>October 31, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "      <td>By dimitri antoni and maggi giust data science...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust Data Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>October 17, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago , Codeup launc...</td>\n",
       "      <td>By dimitri antoni A week ago, codeup launch ou...</td>\n",
       "      <td>By Dimitri Antoniou A week ago, Codeup launche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "      <td>SA tech job fair the third bi-annu san antonio...</td>\n",
       "      <td>SA Tech Job Fair The third bi-annual San Anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>competitor bootcamp are closing. Is the model ...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      published_date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  September 30, 2018   \n",
       "1                                 Data Science Myths    October 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...    October 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair     August 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...     August 14, 2018   \n",
       "\n",
       "                                          blog_image  \\\n",
       "0  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "1  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "2  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            original  \\\n",
       "0  The rumors are true! The time has arrived. Cod...   \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...   \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...   \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  The rumors are true ! The time has arrived. Co...   \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...   \n",
       "2  By Dimitri Antoniou\\nA week ago , Codeup launc...   \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  the rumor are true! the time ha arrived. codeu...   \n",
       "1  By dimitri antoni and maggi giust data science...   \n",
       "2  By dimitri antoni A week ago, codeup launch ou...   \n",
       "3  SA tech job fair the third bi-annu san antonio...   \n",
       "4  competitor bootcamp are closing. Is the model ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  The rumor are true! The time ha arrived. Codeu...  \n",
       "1  By Dimitri Antoniou and Maggie Giust Data Scie...  \n",
       "2  By Dimitri Antoniou A week ago, Codeup launche...  \n",
       "3  SA Tech Job Fair The third bi-annual San Anton...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Codeup_edited_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Ask yourself:\n",
    "   - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "        - answer: Due to size I would use lemmatized\n",
    "        \n",
    "        \n",
    "   - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "        - answer: Due to size I would use lemmatized\n",
    " \n",
    " \n",
    "   - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "        - answer: Due to size I would use stemmed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
